# ğŸš¦ **BogotÃ¡ Traffic Vision**

[![Ultralytics CI](https://img.shields.io/badge/Ultralytics%20CI-passing-brightgreen)](https://github.com/ultralytics/ultralytics/actions)  [![Open in Kaggle](https://img.shields.io/badge/Open_in-Kaggle-blue)]() [![Paper (PDF)](https://img.shields.io/badge/Paper-PDF-green?logo=google-drive)](https://drive.google.com/file/d/1voYwoui9uE1eeHH7lskjdRdDJow13RoI/view?usp=sharing)

An intelligent, real-time vehicle flow detection system for optimizing urban mobility in BogotÃ¡ using state-of-the-art computer vision and deep learning techniques. Leveraging Python, OpenCV, Ultralytics YOLO, and BYTETRACK, this framework ingests live or recorded video streams from existing CCTV infrastructure, processes each frame for object detection, tracks vehicle trajectories, and performs line-cross counting to yield accurate vehicle flow statistics in under 10â€¯ms per frame. Its modular design allows seamless benchmarking across multiple YOLO variants, facilitating data-driven decisions for adaptive traffic signaling and congestion management. ğŸ™ï¸ğŸš—

<p align="center">
  <img src="https://raw.githubusercontent.com/BCCRO/vision-urbana-bogota/main/media/4K%20Road%20traffic%20video_count.gif" alt="Model Demo" />
</p>

---

## ğŸ“– Overview

This repository provides a modular pipeline to detect, track, and count vehicles in live or recorded video streams leveraging YOLO and BYTETRACK. Key objectives include:

* Leveraging existing urban camera infrastructure
* Comparing YOLOv8/9/10/11 for accuracy and throughput
* Implementing robust line-cross counting logic
* Enabling data-driven adaptive traffic control and alerts

---

## ğŸ“ˆ Results

Evaluation across YOLOv8â€“YOLOv11 models revealed that YOLOv10-m achieved the most favorable trade-off between accuracy and speed, reporting a mAPâ‚…â‚€â€“â‚‰â‚… of 0.848, precision of 0.906, recall of 0.881, and an average throughput of 250â€¯FPS on 4â€¯K video input. Inference trials on a 500-frame test sequence recorded 19 vehicles with a mean latency of 4â€¯ms per frame, demonstrating consistent performance in high-resolution urban scenarios. These metrics underscore the suitability of the proposed system for real-world deployment in BogotÃ¡â€™s traffic monitoring network.

---

## ğŸ—‚ï¸ Repository Structure

```text
vision-urbana-bogota/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ data.yaml            # Dataset configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ train/           # Raw training images & labels
â”‚   â”‚   â””â”€â”€ val/             # Raw validation images & labels
â”‚   â”œâ”€â”€ interim/             # Intermediate processed data
â”‚   â””â”€â”€ processed/           # Final data for training
â”œâ”€â”€ media/                   # GIFs, figures, and demo assets
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploracion.ipynb
â”‚   â”œâ”€â”€ 02_data_prep.ipynb
â”‚   â”œâ”€â”€ 03_train_compare.ipynb
â”‚   â””â”€â”€ 04_video_inference.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_yolo.py        # Training script
â”‚   â””â”€â”€ val_yolo.py          # Validation & metrics extraction
â”œâ”€â”€ models/                  # Trained model weights
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ runs_compare_all/    # Training logs & plots
â”‚   â””â”€â”€ video_inference/     # Inference videos
â””â”€â”€   
```

---

## ğŸš€ Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/BCCRO/vision-urbana-bogota.git
   cd vision-urbana-bogota
   ```
2. **Set up environment**

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

---

## ğŸš€ Quick Start

**Train all models:**

```bash
python src/train_yolo.py
```

**Validate and collect metrics:**

```bash
python src/val_yolo.py
```

**Run inference demo:**

```bash
jupyter nbconvert --to notebook --execute notebooks/04_video_inference.ipynb
```

---

## ğŸ“œ Resources

* **Ultralytics YOLO** for object detection framework
* **Kaggle Dataset**: Car Detection and Tracking Dataset (Kaggle)

---

## ğŸ–‹ï¸ Authors

* **Briyid Catalina Cruz Ostos** ([bccruzo@udistrital.edu.co](mailto:bccruzo@udistrital.edu.co))
